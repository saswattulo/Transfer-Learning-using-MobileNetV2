{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a71a8e0",
   "metadata": {
    "papermill": {
     "duration": 0.005323,
     "end_time": "2024-04-13T10:39:17.750411",
     "exception": false,
     "start_time": "2024-04-13T10:39:17.745088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "  <style>\n",
    "    h1 {\n",
    "      text-align: center;\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h1>Transfer Learning with MobileNetV2 ü§ñüì∏</h1>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028a186",
   "metadata": {
    "papermill": {
     "duration": 0.004606,
     "end_time": "2024-04-13T10:39:17.759949",
     "exception": false,
     "start_time": "2024-04-13T10:39:17.755343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Introduction ‚ÑπÔ∏è\n",
    "### Transfer learning is a machine learning technique where a model trained on one task is re-purposed on a second related task. \n",
    "### In this notebook, we'll explore how to use transfer learning with the MobileNetV2 architecture for brain MRI tumour detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef98e65",
   "metadata": {
    "papermill": {
     "duration": 0.004488,
     "end_time": "2024-04-13T10:39:17.769046",
     "exception": false,
     "start_time": "2024-04-13T10:39:17.764558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *1.1 What is Transfer Learning? üîÑ*\n",
    "#### Transfer learning involves leveraging the knowledge gained while solving one problem and applying it to a different, but related problem.\n",
    "#### Instead of starting the learning process from scratch, transfer learning allows us to use pre-trained models as a starting point and then fine-tune them for our specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f71cd5",
   "metadata": {
    "papermill": {
     "duration": 0.004603,
     "end_time": "2024-04-13T10:39:17.778374",
     "exception": false,
     "start_time": "2024-04-13T10:39:17.773771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *1.2 Advantages of Transfer Learning:*\n",
    "#### **Reduced Training Time**: Transfer learning significantly reduces training time since we start with pre-trained weights that have already learned meaningful features.\n",
    "#### **Less Data Required**: It allows us to achieve good performance even with less labeled data, as compared to training a model from scratch.\n",
    "#### **Improved Generalization**: Pre-trained models have learned features from a diverse range of data, which often leads to better generalization on new tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452fa25",
   "metadata": {
    "papermill": {
     "duration": 0.00452,
     "end_time": "2024-04-13T10:39:17.787708",
     "exception": false,
     "start_time": "2024-04-13T10:39:17.783188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *1.3 Use Cases of Transfer Learning:*\n",
    "### Transfer learning has found applications in various domains, including:\n",
    "\n",
    "#### 1. **Image Classification**: Classifying images into different categories.\n",
    "#### 2. **Object Detection**: Identifying and locating objects within images.\n",
    "#### 3. **Natural Language Processing (NLP)**: Tasks such as sentiment analysis, text classification, and language translation.\n",
    "#### 4. **Healthcare**: Diagnosing diseases from medical images like MRI scans and X-rays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9af9c",
   "metadata": {
    "papermill": {
     "duration": 0.004409,
     "end_time": "2024-04-13T10:39:17.797070",
     "exception": false,
     "start_time": "2024-04-13T10:39:17.792661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Importing tools (I mean libraries and packages ) ‚öôÔ∏èüì¶\n",
    "\n",
    "##### Let's start by importing the necessary libraries and packages for our project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c42202",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-13T10:39:17.808068Z",
     "iopub.status.busy": "2024-04-13T10:39:17.807740Z",
     "iopub.status.idle": "2024-04-13T10:39:31.039007Z",
     "shell.execute_reply": "2024-04-13T10:39:31.037967Z"
    },
    "papermill": {
     "duration": 13.23946,
     "end_time": "2024-04-13T10:39:31.041432",
     "exception": false,
     "start_time": "2024-04-13T10:39:17.801972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 10:39:21.359743: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-13 10:39:21.359843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-13 10:39:21.482219: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16,EfficientNetV2M\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1eab4",
   "metadata": {
    "papermill": {
     "duration": 0.004864,
     "end_time": "2024-04-13T10:39:31.051974",
     "exception": false,
     "start_time": "2024-04-13T10:39:31.047110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Restructuring the training and validation directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a96deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T10:39:31.063651Z",
     "iopub.status.busy": "2024-04-13T10:39:31.063083Z",
     "iopub.status.idle": "2024-04-13T10:39:31.964705Z",
     "shell.execute_reply": "2024-04-13T10:39:31.963563Z"
    },
    "papermill": {
     "duration": 0.909901,
     "end_time": "2024-04-13T10:39:31.966729",
     "exception": false,
     "start_time": "2024-04-13T10:39:31.056828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images copied successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your \"yes\" and \"no\" folders and training/validation folders\n",
    "yes_folder = '/kaggle/input/brain-mri-images-for-brain-tumor-detection/yes'\n",
    "no_folder = '/kaggle/input/brain-mri-images-for-brain-tumor-detection/no'\n",
    "training_folder = 'training_folder'\n",
    "validation_folder = 'validation_folder'\n",
    "\n",
    "# Create training and validation folders if they don't exist\n",
    "os.makedirs(os.path.join(training_folder, 'yes'), exist_ok=True)\n",
    "os.makedirs(os.path.join(training_folder, 'no'), exist_ok=True)\n",
    "os.makedirs(os.path.join(validation_folder, 'yes'), exist_ok=True)\n",
    "os.makedirs(os.path.join(validation_folder, 'no'), exist_ok=True)\n",
    "\n",
    "# Function to split images and copy them to training and validation folders\n",
    "def split_and_copy(source_folder, training_folder, validation_folder, split_size):\n",
    "    # List all images in the source folder\n",
    "    images = [os.path.join(source_folder, img) for img in os.listdir(source_folder) if img.endswith('.jpg') or img.endswith('.png')]\n",
    "    \n",
    "    # Calculate the number of images to be copied to training and validation sets\n",
    "    num_images = len(images)\n",
    "    num_training_images = int(split_size * num_images)\n",
    "    num_validation_images = num_images - num_training_images\n",
    "    \n",
    "    # Randomly shuffle the list of images\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # Copy images to training folder\n",
    "    for img_path in images[:num_training_images]:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        destination_path = os.path.join(training_folder, img_name)\n",
    "        shutil.copy(img_path, destination_path)\n",
    "        \n",
    "    # Copy images to validation folder\n",
    "    for img_path in images[num_training_images:]:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        destination_path = os.path.join(validation_folder, img_name)\n",
    "        shutil.copy(img_path, destination_path)\n",
    "\n",
    "# Split and copy images from \"yes\" folder\n",
    "split_and_copy(yes_folder, os.path.join(training_folder, 'yes'), os.path.join(validation_folder, 'yes'), 0.8)\n",
    "\n",
    "# Split and copy images from \"no\" folder\n",
    "split_and_copy(no_folder, os.path.join(training_folder, 'no'), os.path.join(validation_folder, 'no'), 0.8)\n",
    "\n",
    "print(\"Images copied successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e9625",
   "metadata": {
    "papermill": {
     "duration": 0.004776,
     "end_time": "2024-04-13T10:39:31.976890",
     "exception": false,
     "start_time": "2024-04-13T10:39:31.972114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data loading and deta pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63c6480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T10:39:31.988288Z",
     "iopub.status.busy": "2024-04-13T10:39:31.987711Z",
     "iopub.status.idle": "2024-04-13T10:39:32.010348Z",
     "shell.execute_reply": "2024-04-13T10:39:32.009536Z"
    },
    "papermill": {
     "duration": 0.030312,
     "end_time": "2024-04-13T10:39:32.012275",
     "exception": false,
     "start_time": "2024-04-13T10:39:31.981963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 137 images belonging to 2 classes.\n",
      "Found 36 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your dataset\n",
    "train_data_dir = '/kaggle/working/training_folder'\n",
    "validation_data_dir = '/kaggle/working/validation_folder'\n",
    "\n",
    "# Define image dimensions\n",
    "img_width, img_height = 224, 224\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Preprocess data and augment images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213bb50c",
   "metadata": {
    "papermill": {
     "duration": 0.005298,
     "end_time": "2024-04-13T10:39:32.023238",
     "exception": false,
     "start_time": "2024-04-13T10:39:32.017940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59292da3",
   "metadata": {
    "papermill": {
     "duration": 0.005212,
     "end_time": "2024-04-13T10:39:32.033909",
     "exception": false,
     "start_time": "2024-04-13T10:39:32.028697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *5.1 Loading the pre-trained MobileNetV2 model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0446b07b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T10:39:32.046400Z",
     "iopub.status.busy": "2024-04-13T10:39:32.046093Z",
     "iopub.status.idle": "2024-04-13T10:39:34.094645Z",
     "shell.execute_reply": "2024-04-13T10:39:34.093852Z"
    },
    "papermill": {
     "duration": 2.05681,
     "end_time": "2024-04-13T10:39:34.096974",
     "exception": false,
     "start_time": "2024-04-13T10:39:32.040164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8b8dfa",
   "metadata": {
    "papermill": {
     "duration": 0.005402,
     "end_time": "2024-04-13T10:39:34.108562",
     "exception": false,
     "start_time": "2024-04-13T10:39:34.103160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *5.2 Add custom classification layers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d275033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T10:39:34.121296Z",
     "iopub.status.busy": "2024-04-13T10:39:34.120993Z",
     "iopub.status.idle": "2024-04-13T10:39:34.179579Z",
     "shell.execute_reply": "2024-04-13T10:39:34.178803Z"
    },
    "papermill": {
     "duration": 0.067382,
     "end_time": "2024-04-13T10:39:34.181529",
     "exception": false,
     "start_time": "2024-04-13T10:39:34.114147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "# Create final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c348ea",
   "metadata": {
    "papermill": {
     "duration": 0.005508,
     "end_time": "2024-04-13T10:39:34.192572",
     "exception": false,
     "start_time": "2024-04-13T10:39:34.187064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580c75c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-13T10:39:34.204986Z",
     "iopub.status.busy": "2024-04-13T10:39:34.204512Z",
     "iopub.status.idle": "2024-04-13T10:40:13.122210Z",
     "shell.execute_reply": "2024-04-13T10:40:13.121181Z"
    },
    "papermill": {
     "duration": 38.926808,
     "end_time": "2024-04-13T10:40:13.124880",
     "exception": false,
     "start_time": "2024-04-13T10:39:34.198072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m48s\u001b[0m 16s/step - accuracy: 0.5625 - loss: 1.8205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713004790.926764      86 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1713004790.960119      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5659 - loss: 34.1909 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1713004797.231391      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3s/step - accuracy: 0.5727 - loss: 35.0414 - val_accuracy: 0.4688 - val_loss: 43.1977\n",
      "Epoch 2/10\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4688 - loss: 39.5669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1713004800.745766      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.4688 - loss: 39.5669 - val_accuracy: 0.7500 - val_loss: 9.8118\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1713004804.818135      84 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7404 - loss: 9.9290 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6875 - loss: 12.3924 - val_accuracy: 0.8125 - val_loss: 4.3324\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8084 - loss: 3.5741 - val_accuracy: 0.7500 - val_loss: 0.9518\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 3.8447 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.8265 - loss: 4.3778 - val_accuracy: 0.8438 - val_loss: 1.4942\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8438 - loss: 1.8065 - val_accuracy: 1.0000 - val_loss: 2.9802e-08\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.8987 - loss: 3.5042 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8438 - loss: 6.0854 - val_accuracy: 0.8125 - val_loss: 5.1319\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)\n",
    "\n",
    "# Save the model\n",
    "model.save('brain_mri_transfer_learning_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da61be5d",
   "metadata": {
    "papermill": {
     "duration": 0.00869,
     "end_time": "2024-04-13T10:40:13.142927",
     "exception": false,
     "start_time": "2024-04-13T10:40:13.134237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7.Conclusion üéâ\n",
    "\n",
    "#### In this notebook, we explored the concept of transfer learning and its application using the MobileNetV2 architecture. We learned that transfer learning can significantly reduce training time, require less labeled data, and improve model generalization.\n",
    "#### By leveraging pre-trained models like MobileNetV2, we can efficiently tackle image classification tasks with high accuracy and efficiency.\n",
    "\n",
    "#### Transfer learning has become an indispensable tool in the machine learning toolkit, enabling practitioners to achieve remarkable results across various domains with less effort and computational resources.\n",
    "#### As we continue to explore and experiment with transfer learning techniques, we can expect even more exciting advancements and applications in the field of deep learning.\n",
    "\n",
    "### I hope this notebook has provided valuable insights and inspiration for your future projects.\n",
    "### Happy learning and experimenting with transfer learning! üöÄüî¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571e752",
   "metadata": {
    "papermill": {
     "duration": 0.009259,
     "end_time": "2024-04-13T10:40:13.160985",
     "exception": false,
     "start_time": "2024-04-13T10:40:13.151726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Upvote, Fork, and Make Changes üëçüç¥‚úèÔ∏è\n",
    "### If you found this notebook helpful or have any suggestions for improvement, please consider upvoting, forking the notebook, and making changes. Your feedback and contributions are greatly appreciated!\n",
    "\n",
    "## Follow and Visit My Other Works üìöüîç\n",
    "### Don't forget to [follow me on Kaggle](https://www.kaggle.com/saswattulo) to stay updated with my latest works. You can also visit my other notebooks and kernels for more insights and tutorials."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 165566,
     "sourceId": 377107,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 60.192237,
   "end_time": "2024-04-13T10:40:15.193478",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-13T10:39:15.001241",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
